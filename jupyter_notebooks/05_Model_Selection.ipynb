{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Model Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "* Do a grid search using cross-validation in order to select a classification model.\n",
        "\n",
        "## Inputs\n",
        "* The train and test data set aside in the the last notebook.\n",
        "* The pipeline that was produced in the last notebook.\n",
        "* Parameter values determined in previous notebook.\n",
        "\n",
        "## Outputs\n",
        "* A choice of classification model that we will further tune and evaluate.\n",
        "\n",
        "## Additional Comments\n",
        "* We have chosen to do classification. We may yet do a regression model on the point differential.      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory\n",
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/pp5-ml-dashboard\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "home_dir = '/workspace/pp5-ml-dashboard'\n",
        "os.chdir(home_dir)\n",
        "current_dir = os.getcwd()\n",
        "print(current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now load our training and test sets, as well as some of the packages that we will be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from src.utils import get_df, save_df\n",
        "\n",
        "train_dir = 'train/csv'\n",
        "X_TrainSet = get_df('X_TrainSet',train_dir)\n",
        "Y_TrainSet = get_df('Y_TrainSet',train_dir)\n",
        "\n",
        "test_dir = 'test/csv'\n",
        "X_TestSet = get_df('X_TestSet',test_dir)\n",
        "Y_TestSet = get_df('Y_TestSet',test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Full Pipeline\n",
        "We will build the full pipeline here. It will accept some parameters so that we can tune it later. We also declare some constants that we established in the last notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.selection import DropFeatures, SmartCorrelatedSelection\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# Constants needed for feature engineering\n",
        "META = ['season', 'play_off']\n",
        "THRESH = 0.85\n",
        "TRANSFORMS = {'log_e':(vt.LogTransformer, False), \n",
        "                'log_10':(vt.LogTransformer,'10'),\n",
        "                'reciprocal':(vt.ReciprocalTransformer,False), \n",
        "                'power':(vt.PowerTransformer,False),\n",
        "                'box_cox':(vt.BoxCoxTransformer,False),\n",
        "                'yeo_johnson':(vt.YeoJohnsonTransformer,False)}\n",
        "TRANSFORM_ASSIGNMENTS = {\n",
        "    'yeo_johnson': ['dreb_away', 'blk_home', 'oreb_away', 'fta_away', 'dreb_home', \n",
        "                    'ast_home', 'stl_away', 'pts_away', 'stl_home', 'reb_away',\n",
        "                    'pts_home', 'fgm_away', 'oreb_home', 'pf_away', 'pf_home'],\n",
        "    'box_cox': ['ast_away', 'fta_home']\n",
        "                            }\n",
        "\n",
        "\n",
        "def pipeline(to_drop=None,thresh=THRESH, \n",
        "             transform_assignments=TRANSFORM_ASSIGNMENTS):\n",
        "    if not to_drop:\n",
        "        to_drop = META\n",
        "    else:\n",
        "        to_drop.extend(META)\n",
        "    pipeline = Pipeline([\n",
        "        ('dropper', DropFeatures(features_to_drop=to_drop)),\n",
        "        ('corr_selector', SmartCorrelatedSelection(method=\"pearson\",\n",
        "                                                   threshold=thresh,\n",
        "                                                   selection_method=\"variance\",))\n",
        "                        ])\n",
        "    for transform in transform_assignments:\n",
        "        pipeline.steps.append(\n",
        "            (transform, TRANSFORMS[transform](variables=transform_assignments[transform]))\n",
        "        )\n",
        "    pipeline.steps.append(('scaler', StandardScaler()))\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "MODELS = {\n",
        "    'LogisticRegression': LogisticRegression,\n",
        "    'DecisionTree': DecisionTreeClassifier,\n",
        "    'RandomForest': RandomForestClassifier,\n",
        "    'GradientBoosting': GradientBoostingClassifier,\n",
        "    'ExtraTrees': ExtraTreesClassifier,\n",
        "    'AdaBoost': AdaBoostClassifier,\n",
        "    'XGBoost': XGBClassifier\n",
        "}\n",
        "\n",
        "\n",
        "def add_feat_selection_n_model(pipeline,model,**params):\n",
        "    pipeline.steps.append((\"feat_selection\", SelectFromModel(MODELS[model])))\n",
        "    pipeline.steps.append((model,MODELS[model](**params)))\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
