{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Feature Selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "* Do a grid search using cross-validation in order to select a classification model. We will run this grid search several times removing different features in order to test our Hytpothesis # something and construct non-trivial models.\n",
        "\n",
        "## Inputs\n",
        "* The train and test data set aside in the the last notebook.\n",
        "* The pipeline that was produced in the last notebook.\n",
        "* Parameter values determined in previous notebook.\n",
        "\n",
        "## Outputs\n",
        "* A choice of classification model that we will further tune and evaluate.\n",
        "\n",
        "## Additional Comments\n",
        "* We have chosen to do classification. We may yet do a regression model on the point differential.      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory\n",
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/workspace/pp5-ml-dashboard\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "home_dir = '/workspace/pp5-ml-dashboard'\n",
        "os.chdir(home_dir)\n",
        "current_dir = os.getcwd()\n",
        "print(current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now load our training and test sets, as well as some of the packages that we will be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from src.utils import get_df, save_df\n",
        "\n",
        "train_dir = 'train/csv'\n",
        "X_TrainSet = get_df('X_TrainSet',train_dir)\n",
        "Y_TrainSet = get_df('Y_TrainSet',train_dir)\n",
        "\n",
        "test_dir = 'test/csv'\n",
        "X_TestSet = get_df('X_TestSet',test_dir)\n",
        "Y_TestSet = get_df('Y_TestSet',test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 1: Full Pipeline\n",
        "We will build the full pipeline here. It will accept some parameters so that we can tune it later. We also declare some constants that we established in the last notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.selection import DropFeatures, SmartCorrelatedSelection\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# Constants needed for feature engineering\n",
        "META = ['season', 'play_off']\n",
        "TRIVIAL = ['pts_home','pts_away','plus_minus_home']\n",
        "THRESH = 0.85\n",
        "TRANSFORMS = {'log_e':(vt.LogTransformer, False), \n",
        "                'log_10':(vt.LogTransformer,'10'),\n",
        "                'reciprocal':(vt.ReciprocalTransformer,False), \n",
        "                'power':(vt.PowerTransformer,False),\n",
        "                'box_cox':(vt.BoxCoxTransformer,False),\n",
        "                'yeo_johnson':(vt.YeoJohnsonTransformer,False)}\n",
        "TRANSFORM_ASSIGNMENTS = {\n",
        "    'yeo_johnson': ['dreb_away', 'blk_home', 'oreb_away', 'fta_away', 'dreb_home', \n",
        "                    'ast_home', 'stl_away', 'pts_away', 'stl_home', 'reb_away',\n",
        "                    'pts_home', 'fgm_away', 'oreb_home', 'pf_away', 'pf_home'],\n",
        "    'box_cox': ['ast_away', 'fta_home']\n",
        "                            }\n",
        "\n",
        "\n",
        "def base_pipeline(to_drop=None,thresh=THRESH):\n",
        "    if not to_drop:\n",
        "        to_drop = META\n",
        "    else:\n",
        "        to_drop.extend(META)\n",
        "    to_drop = list(set(to_drop))\n",
        "    pipeline = Pipeline([\n",
        "        ('dropper', DropFeatures(features_to_drop=to_drop)),\n",
        "        ('corr_selector', SmartCorrelatedSelection(method=\"pearson\",\n",
        "                                                   threshold=thresh,\n",
        "                                                   selection_method=\"variance\")\n",
        "                                                   )\n",
        "                        ])\n",
        "    pipeline.to_drop = to_drop\n",
        "    return pipeline\n",
        "\n",
        "    \n",
        "def add_transformations(pipeline, transform_assignments):\n",
        "    # This needs to be called after the above is fit so that the correlation selector has that attr\n",
        "    to_drop = pipeline.to_drop\n",
        "    dropping = set(to_drop + pipeline['corr_selector'].features_to_drop_)\n",
        "    \n",
        "    new_assignments = { key: [val for val in value if val not in dropping] \n",
        "                       for key,value in transform_assignments.items()}\n",
        "    ''' Olde version\n",
        "    for value in transform_assignments.values():\n",
        "        for drop_term in dropping:\n",
        "            if drop_term in value:\n",
        "                value.remove(drop_term)\n",
        "    '''\n",
        "    for transform, targets in new_assignments.items():\n",
        "        if not targets:\n",
        "            continue\n",
        "        pipeline.steps.append(\n",
        "            (transform, TRANSFORMS[transform][0](variables=targets))\n",
        "            )\n",
        "    pipeline.steps.append(('scaler', StandardScaler()))\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We add the last two steps of the pipeline, the feature selection and the model itself. We do this in a separate step since it depends on the model.\n",
        "\n",
        "After a first pass, we will see that our models only use the features in `TRIVIAL`. These features make the classification problem too ... trivial as the winner of the game can be computed directly from `'plus_minus_home'`. The points of the each team can be used together to compute the winner as well, so we also remove them. \n",
        "\n",
        "# Attention\n",
        "this could probably be implimented better with classes, but I think I don't want to worry too much about inheritance, I could do it with composition, and then tune the hyperparameters via methods. Do that later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "MODELS = {\n",
        "    'LogisticRegression': LogisticRegression,\n",
        "    'DecisionTree': DecisionTreeClassifier,\n",
        "    'RandomForest': RandomForestClassifier,\n",
        "    'GradientBoosting': GradientBoostingClassifier,\n",
        "    'ExtraTrees': ExtraTreesClassifier,\n",
        "    'AdaBoost': AdaBoostClassifier,\n",
        "    'XGBoost': XGBClassifier\n",
        "}\n",
        "\n",
        "\n",
        "def add_feat_selection_n_model(pipeline,model_name,random_state=42):\n",
        "    model = MODELS[model_name](random_state=random_state)\n",
        "    pipeline.steps.append((\"feat_selection\", SelectFromModel(model)))\n",
        "    pipeline.steps.append((model_name,model))\n",
        "    return pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us now create our list of models that we are going to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_pipelines(to_drop=None,thresh=THRESH):\n",
        "    PIPELINES = {}\n",
        "    for model_name in MODELS:\n",
        "        base_pipe = base_pipeline(to_drop,thresh)\n",
        "        base_pipe.fit(X_TrainSet)\n",
        "        pipe_w_transforms= add_transformations(base_pipe,TRANSFORM_ASSIGNMENTS)\n",
        "        PIPELINES[model_name] = add_feat_selection_n_model(pipe_w_transforms,model_name)\n",
        "    return PIPELINES\n",
        "PIPELINES = create_pipelines(thresh=0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Section 2: Cross Validation Search\n",
        "We are going to perform multiple grid searchs as we refine our selection of features. The final grid search will determine the best model for our data, which we will tune in the next notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have a few different Hypotheses. One of them, hypothesis 1, is that the models will gravitate strongly towards the features related to points. In order of estimated impact, they are:\n",
        "* `'plus_minus'`\n",
        "* `'pts'`\n",
        "* `'fgm'`\n",
        "* `'fg3m'`, `'ftm'`\n",
        "\n",
        "We will start by training our model on all of these features. To test our hypothesis, we will remove one collection of features at a time until we are left with no features that help you directly determine the score (and hence winner). We will check which features the models use along the way to see if we can validate our hypothesis. We expect that the earlier models will be able to predict the outcome of the games flawlessly.\n",
        "\n",
        "We won't be passing any parameters as we will tune the hyperparameters in the following notebook.\n",
        "\n",
        "Note: we are silencing warnings below. These warnings generate  hundreds of lines and no exceptions are raised."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "import logging\n",
        "logging.captureWarnings(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# to suppress warnings, I think\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "import logging\n",
        "logging.captureWarnings(True)\n",
        "os.environ['PYTHONWARNINGS']='ignore'\n",
        "\n",
        "\n",
        "def grid_search(X_train, y_train, pipelines,param_grid={}):\n",
        "    GRIDS = {}\n",
        "    count = 0\n",
        "    for pipe_name, pipe in pipelines.items():\n",
        "        print(f\"### Beginning grid search for {pipe_name} ###\")\n",
        "        grid=GridSearchCV(estimator=pipe,\n",
        "                    param_grid=param_grid,\n",
        "                    cv=5,\n",
        "                    n_jobs=-2,\n",
        "                    verbose=3,\n",
        "                    scoring=['accuracy','precision'],\n",
        "                    refit='precision')\n",
        "        grid.fit(X_train,y_train)\n",
        "        GRIDS[pipe_name] = grid\n",
        "        count +=1\n",
        "        print(f\"Finished with model {count}.\")\n",
        "        print(f\"{len(pipelines.keys())-count} models remaining.\")\n",
        "    return GRIDS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Beginning grid search for LogisticRegression ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   2.7s\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "[CV 4/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.8s\n",
            "Finished with model 1.\n",
            "6 models remaining.\n",
            "### Beginning grid search for DecisionTree ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "[CV 4/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "Finished with model 2.\n",
            "5 models remaining.\n",
            "### Beginning grid search for RandomForest ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   4.7s\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   4.8s\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   4.9s\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   5.0s\n",
            "[CV 4/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   5.0s\n",
            "Finished with model 3.\n",
            "4 models remaining.\n",
            "### Beginning grid search for GradientBoosting ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   6.0s\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   6.3s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   6.3s\n",
            "[CV 4/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   6.2s\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   6.1s\n",
            "Finished with model 4.\n",
            "3 models remaining.\n",
            "### Beginning grid search for ExtraTrees ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   5.4s\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   5.5s\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   5.8s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   5.5s\n",
            "[CV 4/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   5.6s\n",
            "Finished with model 5.\n",
            "2 models remaining.\n",
            "### Beginning grid search for AdaBoost ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   1.3s\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   1.3s\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   1.3s\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   1.5s\n",
            "[CV 4/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   1.5s\n",
            "Finished with model 6.\n",
            "1 models remaining.\n",
            "### Beginning grid search for XGBoost ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   2.3s\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   2.6s\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   2.6s\n",
            "[CV 4/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   2.6s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   2.6s\n",
            "Finished with model 7.\n",
            "0 models remaining.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "GRIDS = grid_search(X_TrainSet,Y_TrainSet,PIPELINES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see from the above that the models are \"flawless.\" The reports in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use the following code to generate reports for evaluating our models. You can pass one of the resulting pipelines to `'clf_performance'` or the whole grid to `'grid_search_report_best'` if you like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['LogisticRegression', 'DecisionTree', 'RandomForest', 'GradientBoosting', 'ExtraTrees', 'AdaBoost', 'XGBoost'])\n",
            "Best LogisticRegression model: Avg. Precision: 100.0%.\n",
            "                               Avg. Accuracy: 100.0%.\n",
            "\n",
            "Best DecisionTree model: Avg. Precision: 100.0%.\n",
            "                         Avg. Accuracy: 100.0%.\n",
            "\n",
            "Best RandomForest model: Avg. Precision: 100.0%.\n",
            "                         Avg. Accuracy: 100.0%.\n",
            "\n",
            "Best GradientBoosting model: Avg. Precision: 100.0%.\n",
            "                             Avg. Accuracy: 100.0%.\n",
            "\n",
            "Best ExtraTrees model: Avg. Precision: 100.0%.\n",
            "                       Avg. Accuracy: 100.0%.\n",
            "\n",
            "Best AdaBoost model: Avg. Precision: 100.0%.\n",
            "                     Avg. Accuracy: 100.0%.\n",
            "\n",
            "Best XGBoost model: Avg. Precision: 100.0%.\n",
            "                    Avg. Accuracy: 100.0%.\n",
            "\n",
            "LogisticRegression\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "DecisionTree\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "RandomForest\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "GradientBoosting\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "ExtraTrees\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            2       5226\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "AdaBoost\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "XGBoost\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from src.model_eval import clf_performance, get_best_scores, grid_search_report_best\n",
        "\n",
        "print(GRIDS.keys())\n",
        "def extract_best_estimator(grid_collection, model_name):\n",
        "  return grid_collection[model_name].best_estimator_\n",
        "\n",
        "def get_best_scores(grid_collection):\n",
        "  for name, grid in grid_collection.items():\n",
        "      res = (pd.DataFrame(grid.cv_results_)\n",
        "         .sort_values(by=['mean_test_precision','mean_test_accuracy'],ascending=False)\n",
        "         .filter(['params','mean_test_precision','mean_test_accuracy'])\n",
        "        .values)\n",
        "      intro = f\"Best {name} model:\"\n",
        "      print(f\"{intro} Avg. Precision: {res[0][1]*100}%.\")\n",
        "      print(f\"{len(intro)*' '} Avg. Accuracy: {res[0][2]*100}%.\")\n",
        "      print()\n",
        "\n",
        "get_best_scores(GRIDS)\n",
        "\n",
        "grid_search_report_best(GRIDS,X_TrainSet,Y_TrainSet,X_TestSet,Y_TestSet,['loss','win'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Simply uncomment out the last line to look at a report for the best estimator of each type. There were 2 incorrect predictions, both made by the `ExtraTrees` model. This is as we expected. The points scored in the game determine who wins, and we have a lot of that data still present. Let's recall which features we train on. Some features that we dropped were common to each model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['season', 'play_off']\n",
            "['fgm_home', 'fg3m_home', 'ftm_home', 'dreb_home', 'ast_home', 'stl_home', 'pf_home', 'fgm_away', 'fg3a_away', 'ftm_away', 'dreb_away', 'ast_away', 'stl_away', 'pf_away']\n"
          ]
        }
      ],
      "source": [
        "print(META)\n",
        "sample_pipe = GRIDS['LogisticRegression'].best_estimator_\n",
        "corr_dropped = list(sample_pipe['corr_selector'].features_to_drop_)\n",
        "print(corr_dropped)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So some of the point related features were removed. But plus/minus score and actual scores were still retained.\n",
        "In the end, each model was only trained an the following features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression used:\n",
            "Index(['pts_home', 'plus_minus_home', 'pts_away'], dtype='object')\n",
            "DecisionTree used:\n",
            "Index(['plus_minus_home'], dtype='object')\n",
            "RandomForest used:\n",
            "Index(['pts_home', 'plus_minus_home', 'pts_away'], dtype='object')\n",
            "GradientBoosting used:\n",
            "Index(['plus_minus_home'], dtype='object')\n",
            "ExtraTrees used:\n",
            "Index(['pts_home', 'plus_minus_home', 'pts_away'], dtype='object')\n",
            "AdaBoost used:\n",
            "Index(['plus_minus_home'], dtype='object')\n",
            "XGBoost used:\n",
            "Index(['plus_minus_home'], dtype='object')\n",
            "All models used: {'plus_minus_home'}.\n",
            "All models dropped: {'fta_home', 'stl_away', 'pts_away', 'blk_home', 'fta_away', 'ftm_home', 'fga_away', 'blk_away', 'tov_away', 'fg3m_away', 'fg3m_home', 'ast_away', 'dreb_home', 'oreb_away', 'reb_home', 'reb_away', 'fg3a_home', 'fgm_home', 'pf_home', 'dreb_away', 'fgm_away', 'fg3a_away', 'stl_home', 'tov_home', 'ftm_away', 'pts_home', 'fga_home', 'ast_home', 'pf_away', 'oreb_home'}.\n"
          ]
        }
      ],
      "source": [
        "def find_features(X,fitted_pipe, initial_drop):\n",
        "    corr_dropped = list(fitted_pipe['corr_selector'].features_to_drop_)\n",
        "    auto_dropped = initial_drop + corr_dropped\n",
        "    cols = [col for col in X_TrainSet.columns if col not in auto_dropped]\n",
        "\n",
        "    features = fitted_pipe['feat_selection'].get_support()\n",
        "    X = X_TrainSet.filter(cols)\n",
        "    if len(X.columns) != features.shape[0]:\n",
        "        raise ValueError\n",
        "    feat_selected_dropped = []\n",
        "    for index, col in enumerate(X.columns):\n",
        "        if not features[index]:\n",
        "            X.drop(col, axis=1, inplace=True)\n",
        "        else:\n",
        "            feat_selected_dropped.append(col)\n",
        "    return X.columns, auto_dropped + feat_selected_dropped\n",
        "\n",
        "best_pipes = {name: grid.best_estimator_ for name, grid in GRIDS.items()}\n",
        "def find_overlaps(best_pipes,initial_drop):\n",
        "    feat_lists = [set(find_features(X_TrainSet,pipe,initial_drop)[0]) for pipe in best_pipes.values()]\n",
        "    overlap_kept = set.intersection(*feat_lists)\n",
        "    overlap_dropped = set.difference(set(X_TrainSet.columns),overlap_kept)\n",
        "    overlap_dropped = set.difference(overlap_dropped, set(META))\n",
        "    return overlap_kept, overlap_dropped\n",
        "for pipe_name, pipe in best_pipes.items():\n",
        "    print(pipe_name, \"used:\")\n",
        "    kept, dropped = find_features(X_TrainSet,pipe,META)\n",
        "    print(kept)\n",
        "overlap_kept, overlap_dropped = find_overlaps(best_pipes,META)\n",
        "print(f\"All models used: {overlap_kept}.\")\n",
        "print(f\"All models dropped: {overlap_dropped}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This a large step towards validating our first hypothesis. Let's remove `'plus_minus_home'` and see how this impacts the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Beginning grid search for LogisticRegression ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "[CV 4/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.7s\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.8s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.8s\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.8s\n",
            "Finished with model 1.\n",
            "6 models remaining.\n",
            "### Beginning grid search for DecisionTree ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 3/5] END . accuracy: (test=0.999) precision: (test=1.000) total time=   0.8s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.9s\n",
            "[CV 2/5] END . accuracy: (test=0.999) precision: (test=1.000) total time=   0.9s\n",
            "[CV 4/5] END . accuracy: (test=0.999) precision: (test=0.999) total time=   0.9s\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   0.9s\n",
            "Finished with model 2.\n",
            "5 models remaining.\n",
            "### Beginning grid search for RandomForest ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 4/5] END . accuracy: (test=0.999) precision: (test=0.999) total time=  10.5s\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=  10.7s\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=  10.5s\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=  10.1s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=  10.2s\n",
            "Finished with model 3.\n",
            "4 models remaining.\n",
            "### Beginning grid search for GradientBoosting ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 2/5] END . accuracy: (test=0.999) precision: (test=0.999) total time=  13.5s\n",
            "[CV 4/5] END . accuracy: (test=0.998) precision: (test=0.999) total time=  13.6s\n",
            "[CV 3/5] END . accuracy: (test=0.999) precision: (test=0.999) total time=  13.6s\n",
            "[CV 1/5] END . accuracy: (test=0.999) precision: (test=0.999) total time=  13.7s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=  13.8s\n",
            "Finished with model 4.\n",
            "3 models remaining.\n",
            "### Beginning grid search for ExtraTrees ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 4/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   8.4s\n",
            "[CV 3/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   8.5s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   8.8s\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   8.9s\n",
            "[CV 2/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   9.0s\n",
            "Finished with model 5.\n",
            "2 models remaining.\n",
            "### Beginning grid search for AdaBoost ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END . accuracy: (test=0.988) precision: (test=0.985) total time=   4.2s\n",
            "[CV 3/5] END . accuracy: (test=0.989) precision: (test=0.989) total time=   4.1s\n",
            "[CV 2/5] END . accuracy: (test=0.986) precision: (test=0.990) total time=   4.1s\n",
            "[CV 5/5] END . accuracy: (test=0.988) precision: (test=0.989) total time=   4.1s\n",
            "[CV 4/5] END . accuracy: (test=0.987) precision: (test=0.986) total time=   4.2s\n",
            "Finished with model 6.\n",
            "1 models remaining.\n",
            "### Beginning grid search for XGBoost ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END . accuracy: (test=1.000) precision: (test=1.000) total time=   6.2s\n",
            "[CV 2/5] END . accuracy: (test=0.999) precision: (test=0.999) total time=   6.3s\n",
            "[CV 5/5] END . accuracy: (test=1.000) precision: (test=0.999) total time=   6.4s\n",
            "[CV 4/5] END . accuracy: (test=0.999) precision: (test=0.999) total time=   6.5s\n",
            "[CV 3/5] END . accuracy: (test=0.999) precision: (test=0.999) total time=   6.6s\n",
            "Finished with model 7.\n",
            "0 models remaining.\n"
          ]
        }
      ],
      "source": [
        "PIPELINES_wo_pm = create_pipelines(to_drop=['plus_minus_home'],thresh=0.6)\n",
        "GRIDS_wo_pm = grid_search(X_TrainSet,Y_TrainSet,PIPELINES_wo_pm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unsurprisingly, these models also performed extremely well. `AdaBoost` was the 'worst' performing model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best LogisticRegression model: Avg. Precision: 100.0%.\n",
            "                               Avg. Accuracy: 100.0%.\n",
            "\n",
            "Best DecisionTree model: Avg. Precision: 99.94809538713346%.\n",
            "                         Avg. Accuracy: 99.9455205353326%.\n",
            "\n",
            "Best RandomForest model: Avg. Precision: 99.96697000239465%.\n",
            "                         Avg. Accuracy: 99.96845919239748%.\n",
            "\n",
            "Best GradientBoosting model: Avg. Precision: 99.91977346807073%.\n",
            "                             Avg. Accuracy: 99.91398096083654%.\n",
            "\n",
            "Best ExtraTrees model: Avg. Precision: 99.98584349176355%.\n",
            "                       Avg. Accuracy: 99.9885308769853%.\n",
            "\n",
            "Best AdaBoost model: Avg. Precision: 98.77393315282352%.\n",
            "                     Avg. Accuracy: 98.75272393212981%.\n",
            "\n",
            "Best XGBoost model: Avg. Precision: 99.92451828391368%.\n",
            "                    Avg. Accuracy: 99.93118402880536%.\n",
            "\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13341        348\n",
            "Prediction win           42      21145\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      0.97      0.99     13689\n",
            "         win       0.98      1.00      0.99     21187\n",
            "\n",
            "    accuracy                           0.99     34876\n",
            "   macro avg       0.99      0.99      0.99     34876\n",
            "weighted avg       0.99      0.99      0.99     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3398         93\n",
            "Prediction win           12       5216\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      0.97      0.98      3491\n",
            "         win       0.98      1.00      0.99      5228\n",
            "\n",
            "    accuracy                           0.99      8719\n",
            "   macro avg       0.99      0.99      0.99      8719\n",
            "weighted avg       0.99      0.99      0.99      8719\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "get_best_scores(GRIDS_wo_pm)\n",
        "\n",
        "clf_performance(X_TrainSet,Y_TrainSet,X_TestSet,Y_TestSet,GRIDS_wo_pm['AdaBoost'].best_estimator_,['loss','win'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's see what features were removed and what our models were trained on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression used:\n",
            "Index(['pts_home', 'pts_away'], dtype='object')\n",
            "DecisionTree used:\n",
            "Index(['pts_home', 'pts_away'], dtype='object')\n",
            "RandomForest used:\n",
            "Index(['pts_home', 'pts_away'], dtype='object')\n",
            "GradientBoosting used:\n",
            "Index(['pts_home', 'pts_away'], dtype='object')\n",
            "ExtraTrees used:\n",
            "Index(['pts_home', 'pts_away'], dtype='object')\n",
            "AdaBoost used:\n",
            "Index(['pts_home', 'pts_away'], dtype='object')\n",
            "XGBoost used:\n",
            "Index(['pts_home', 'pts_away'], dtype='object')\n",
            "All models used: {'pts_home', 'pts_away'}.\n",
            "All models dropped: {'fta_home', 'oreb_away', 'stl_away', 'blk_home', 'reb_home', 'reb_away', 'fg3a_home', 'fta_away', 'ftm_home', 'fga_away', 'blk_away', 'tov_away', 'fg3m_away', 'fgm_home', 'pf_home', 'dreb_away', 'fg3m_home', 'fgm_away', 'plus_minus_home', 'ast_away', 'fg3a_away', 'stl_home', 'dreb_home', 'tov_home', 'ftm_away', 'fga_home', 'ast_home', 'pf_away', 'oreb_home'}.\n"
          ]
        }
      ],
      "source": [
        "best_pipes_wo_pm = {name: grid.best_estimator_ for name, grid in GRIDS_wo_pm.items()}\n",
        "initial_drop = ['plus_minus_home'] + META\n",
        "\n",
        "def find_features(X, fitted_pipe, initial_drop):\n",
        "    corr_dropped = list(fitted_pipe['corr_selector'].features_to_drop_)\n",
        "    auto_dropped = initial_drop + corr_dropped\n",
        "    cols = [col for col in X_TrainSet.columns if col not in auto_dropped]\n",
        "\n",
        "    features = fitted_pipe['feat_selection'].get_support()\n",
        "    X = X_TrainSet.filter(cols)\n",
        "    if len(X.columns) != features.shape[0]:\n",
        "        raise ValueError\n",
        "    feat_selected_dropped = []\n",
        "    for index, col in enumerate(X.columns):\n",
        "        if not features[index]:\n",
        "            X.drop(col, axis=1, inplace=True)\n",
        "        else:\n",
        "            feat_selected_dropped.append(col)\n",
        "    return X.columns, auto_dropped + feat_selected_dropped\n",
        "\n",
        "for pipe_name, pipe in best_pipes_wo_pm.items():\n",
        "    print(pipe_name, \"used:\")\n",
        "    kept, dropped = find_features(X_TrainSet, pipe, initial_drop)\n",
        "    print(kept)\n",
        "\n",
        "overlap_kept, overlap_dropped = find_overlaps(best_pipes_wo_pm,initial_drop)\n",
        "print(f\"All models used: {overlap_kept}.\")\n",
        "print(f\"All models dropped: {overlap_dropped}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, they focused completely on the points scored by each team. Despite this, there were some models that made in accurate predictions. Let's go further and remove the points each team scored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Beginning grid search for LogisticRegression ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 2/5] END . accuracy: (test=0.918) precision: (test=0.929) total time=   0.6s\n",
            "[CV 3/5] END . accuracy: (test=0.930) precision: (test=0.935) total time=   0.7s\n",
            "[CV 1/5] END . accuracy: (test=0.926) precision: (test=0.941) total time=   0.7s\n",
            "[CV 4/5] END . accuracy: (test=0.925) precision: (test=0.937) total time=   0.7s\n",
            "[CV 5/5] END . accuracy: (test=0.924) precision: (test=0.934) total time=   0.7s\n",
            "Finished with model 1.\n",
            "6 models remaining.\n",
            "### Beginning grid search for DecisionTree ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        }
      ],
      "source": [
        "PIPELINES_wo_pts = create_pipelines(to_drop=TRIVIAL,thresh=0.6)\n",
        "GRIDS_wo_pts = grid_search(X_TrainSet,Y_TrainSet,PIPELINES_wo_pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This made it more challenging for the models. Lets see what the best performance was and which features the models trained on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The best performing LogisticRegression model had a score of 92.46759519581731%.\n",
            "\n",
            "The best performing DecisionTree model had a score of 84.47069193712802%.\n",
            "\n",
            "The best performing RandomForest model had a score of 88.32435467429548%.\n",
            "\n",
            "The best performing GradientBoosting model had a score of 89.10138272335668%.\n",
            "\n",
            "The best performing ExtraTrees model had a score of 88.51358472263327%.\n",
            "\n",
            "The best performing AdaBoost model had a score of 88.98096618000066%.\n",
            "\n",
            "The best performing XGBoost model had a score of 89.57449319325244%.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "get_best_scores(GRIDS_wo_pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Decision Tree model was the worst and the Logistic Regression was the best. Let's look at the reports of each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       12305       1384\n",
            "Prediction win         1236      19951\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       0.91      0.90      0.90     13689\n",
            "         win       0.94      0.94      0.94     21187\n",
            "\n",
            "    accuracy                           0.92     34876\n",
            "   macro avg       0.92      0.92      0.92     34876\n",
            "weighted avg       0.92      0.92      0.92     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3142        349\n",
            "Prediction win          308       4920\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       0.91      0.90      0.91      3491\n",
            "         win       0.93      0.94      0.94      5228\n",
            "\n",
            "    accuracy                           0.92      8719\n",
            "   macro avg       0.92      0.92      0.92      8719\n",
            "weighted avg       0.92      0.92      0.92      8719\n",
            " \n",
            "\n",
            "DecisionTree\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13668         21\n",
            "Prediction win          328      20859\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       0.98      1.00      0.99     13689\n",
            "         win       1.00      0.98      0.99     21187\n",
            "\n",
            "    accuracy                           0.99     34876\n",
            "   macro avg       0.99      0.99      0.99     34876\n",
            "weighted avg       0.99      0.99      0.99     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        2787        704\n",
            "Prediction win          646       4582\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       0.81      0.80      0.81      3491\n",
            "         win       0.87      0.88      0.87      5228\n",
            "\n",
            "    accuracy                           0.85      8719\n",
            "   macro avg       0.84      0.84      0.84      8719\n",
            "weighted avg       0.84      0.85      0.84      8719\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "target_names = ['LogisticRegression','DecisionTree']\n",
        "two_grids = {name: grid for name, grid in GRIDS_wo_pts.items() if name in target_names}\n",
        "grid_search_report_best(two_grids,X_TrainSet,Y_TrainSet,X_TestSet,Y_TestSet,['loss','win'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are both good models. Their accuracy and precision are within the desired range. Remember, we wanted accuracy above 70% and average precision above 75%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fg3m_home', 'ftm_home', 'dreb_home', 'ast_home', 'stl_home', 'pf_home', 'fg3a_away', 'ftm_away', 'dreb_away', 'ast_away', 'stl_away', 'pf_away']\n",
            "LogisticRegression\n",
            "Index(['fgm_home', 'fg3a_home', 'fta_home', 'fgm_away', 'fg3m_away',\n",
            "       'fta_away'],\n",
            "      dtype='object')\n",
            "DecisionTree\n",
            "Index(['fgm_home', 'fta_home', 'fgm_away', 'fta_away'], dtype='object')\n",
            "RandomForest\n",
            "Index(['fgm_home', 'fta_home', 'fgm_away', 'fta_away'], dtype='object')\n",
            "GradientBoosting\n",
            "Index(['fgm_home', 'fta_home', 'fgm_away', 'fta_away'], dtype='object')\n",
            "ExtraTrees\n",
            "Index(['fgm_home', 'fta_home', 'reb_home', 'fgm_away', 'fta_away', 'reb_away'], dtype='object')\n",
            "AdaBoost\n",
            "Index(['fgm_home', 'fta_home', 'fgm_away', 'fta_away'], dtype='object')\n",
            "XGBoost\n",
            "Index(['fgm_home', 'fta_home', 'fgm_away', 'fta_away'], dtype='object')\n",
            "{'reb_away', 'fgm_home', 'fg3a_home', 'fg3m_away', 'fta_home', 'fgm_away', 'reb_home', 'fta_away'}\n"
          ]
        }
      ],
      "source": [
        "sample_wo_pts = GRIDS_wo_pts['LogisticRegression'].best_estimator_\n",
        "corr_dropped_wo_pts = sample_wo_pts['corr_selector'].features_to_drop_\n",
        "print(corr_dropped_wo_pts)\n",
        "auto_dropped_wo_pts = META + TRIVIAL + corr_dropped_wo_pts\n",
        "remaining_cols_wo_pts = [col for col in X_TrainSet.columns \n",
        "                         if col not in auto_dropped_wo_pts]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "best_pipes = {name: grid.best_estimator_ for name, grid in GRIDS_wo_pts.items()}\n",
        "\n",
        "for pipe_name, pipe in best_pipes.items():\n",
        "    print(pipe_name)\n",
        "    print(find_features(X_TrainSet,pipe,remaining_cols_wo_pts))\n",
        "\n",
        "feat_dict = {name: find_features(X_TrainSet,pipe,remaining_cols_wo_pts) for name,pipe in best_pipes.items()}\n",
        "all_feats = {feat for feats in feat_dict.values() for feat in feats}\n",
        "feat_overlap = []\n",
        "print(all_feats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are some interesting observations here. A lot has been done during the feature selection steps. The '`'corr_selection'` step meant that the (automated)  `'feat_selection'` had less to choose from. \n",
        "\n",
        "Interesting observations:\n",
        "* The Logistic Regression kept the most features and performed the best. It was able to almost completely compute the score of the away team.\n",
        "* \n",
        "\n",
        "# Attention, maybe run an experiment later to see what happens when we remove one/both feature selection steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Beginning grid search for LogisticRegression ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END ..................................., score=1.000 total time=   1.3s\n",
            "[CV 4/5] END ..................................., score=1.000 total time=   1.3s\n",
            "[CV 2/5] END ..................................., score=1.000 total time=   1.4s\n",
            "[CV 3/5] END ..................................., score=1.000 total time=   1.5s\n",
            "[CV 5/5] END ..................................., score=1.000 total time=   1.5s\n",
            "Finished with model 1.\n",
            "6 models remaining.\n",
            "### Beginning grid search for DecisionTree ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 2/5] END ..................................., score=1.000 total time=   0.8s\n",
            "[CV 3/5] END ..................................., score=1.000 total time=   0.8s\n",
            "[CV 4/5] END ..................................., score=1.000 total time=   1.1s\n",
            "[CV 5/5] END ..................................., score=1.000 total time=   1.1s\n",
            "[CV 1/5] END ..................................., score=1.000 total time=   1.3s\n",
            "Finished with model 2.\n",
            "5 models remaining.\n",
            "### Beginning grid search for RandomForest ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 2/5] END ..................................., score=1.000 total time=   5.7s\n",
            "[CV 1/5] END ..................................., score=1.000 total time=   5.9s\n",
            "[CV 5/5] END ..................................., score=1.000 total time=   5.9s\n",
            "[CV 4/5] END ..................................., score=1.000 total time=   6.0s\n",
            "[CV 3/5] END ..................................., score=1.000 total time=   6.2s\n",
            "Finished with model 3.\n",
            "4 models remaining.\n",
            "### Beginning grid search for GradientBoosting ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 5/5] END ..................................., score=1.000 total time=   8.3s\n",
            "[CV 3/5] END ..................................., score=1.000 total time=   8.5s\n",
            "[CV 1/5] END ..................................., score=1.000 total time=   8.5s\n",
            "[CV 2/5] END ..................................., score=1.000 total time=   8.6s\n",
            "[CV 4/5] END ..................................., score=1.000 total time=   8.6s\n",
            "Finished with model 4.\n",
            "3 models remaining.\n",
            "### Beginning grid search for ExtraTrees ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 5/5] END ..................................., score=1.000 total time=   7.0s\n",
            "[CV 4/5] END ..................................., score=1.000 total time=   7.1s\n",
            "[CV 3/5] END ..................................., score=1.000 total time=   7.1s\n",
            "[CV 1/5] END ..................................., score=1.000 total time=   7.2s\n",
            "[CV 2/5] END ..................................., score=1.000 total time=   7.2s\n",
            "Finished with model 5.\n",
            "2 models remaining.\n",
            "### Beginning grid search for AdaBoost ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END ..................................., score=1.000 total time=   1.2s\n",
            "[CV 4/5] END ..................................., score=1.000 total time=   1.2s\n",
            "[CV 2/5] END ..................................., score=1.000 total time=   1.3s\n",
            "[CV 5/5] END ..................................., score=1.000 total time=   1.3s\n",
            "[CV 3/5] END ..................................., score=1.000 total time=   1.4s\n",
            "Finished with model 6.\n",
            "1 models remaining.\n",
            "### Beginning grid search for XGBoost ###\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END ..................................., score=1.000 total time=   3.1s\n",
            "[CV 3/5] END ..................................., score=1.000 total time=   3.2s\n",
            "[CV 4/5] END ..................................., score=1.000 total time=   3.3s\n",
            "[CV 5/5] END ..................................., score=1.000 total time=   3.3s\n",
            "[CV 2/5] END ..................................., score=1.000 total time=   3.3s\n",
            "Finished with model 7.\n",
            "0 models remaining.\n"
          ]
        }
      ],
      "source": [
        "NEW_PIPELINES = create_pipelines()\n",
        "'''fitted_pipelines = {}\n",
        "for pipe_name, pipe in NEW_PIPELINES.items():\n",
        "    pipe.fit(X_TrainSet,Y_TrainSet)\n",
        "    fitted_pipelines[pipe_name] = pipe\n",
        "'''\n",
        "GRIDS_wo_pm = grid_search(X_TrainSet,Y_TrainSet,NEW_PIPELINES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_best_scores(GRIDS):\n",
        "  for grid in GRIDS.values():\n",
        "    res = (pd.DataFrame(grid.cv_results_)\n",
        "       .sort_values(by='mean_test_score',ascending=False)\n",
        "       .filter(['params','mean_test_score'])\n",
        "       .values)\n",
        "\n",
        "    print(res)\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "def confusion_matrix_and_report(X,y,pipeline,label_map):\n",
        "\n",
        "  prediction = pipeline.predict(X)\n",
        "\n",
        "  print('---  Confusion Matrix  ---')\n",
        "  print(pd.DataFrame(confusion_matrix(y_pred=prediction, y_true=y),\n",
        "        columns=[ [\"Actual \" + sub for sub in label_map] ], \n",
        "        index= [ [\"Prediction \" + sub for sub in label_map ]]\n",
        "        ))\n",
        "  print(\"\\n\")\n",
        "\n",
        "\n",
        "  print('---  Classification Report  ---')\n",
        "  print(classification_report(y, prediction, target_names=label_map),\"\\n\")\n",
        "\n",
        "\n",
        "def clf_performance(X_train,y_train,X_test,y_test,pipeline,label_map):\n",
        "  print(\"#### Train Set #### \\n\")\n",
        "  confusion_matrix_and_report(X_train,y_train,pipeline,label_map)\n",
        "\n",
        "  print(\"#### Test Set ####\\n\")\n",
        "  confusion_matrix_and_report(X_test,y_test,pipeline,label_map)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After examining the reports for all of the models in `GRIDS` and those in our new search `GRIDS_wo_pm`, we found that the two worst performing models are still very close to being 100% accurate. They are AdaBoost and ExtraTrees. Other models did fail to be perfect, but these were the only two that did not score 100% across the board on all metrics for the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "DecisionTree\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "RandomForest\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "GradientBoosting\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "ExtraTrees\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "AdaBoost\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "XGBoost\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, grid in GRIDS_wo_pm.items():\n",
        "    print(name)\n",
        "    best_estimator = grid.best_estimator_\n",
        "    clf_performance(X_TrainSet,Y_TrainSet,X_TestSet,Y_TestSet,best_estimator, label_map=['loss', 'win']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ada Boost\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n",
            "Extra Tree\n",
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss       13689          0\n",
            "Prediction win            0      21187\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00     13689\n",
            "         win       1.00      1.00      1.00     21187\n",
            "\n",
            "    accuracy                           1.00     34876\n",
            "   macro avg       1.00      1.00      1.00     34876\n",
            "weighted avg       1.00      1.00      1.00     34876\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                Actual loss Actual win\n",
            "Prediction loss        3491          0\n",
            "Prediction win            0       5228\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        loss       1.00      1.00      1.00      3491\n",
            "         win       1.00      1.00      1.00      5228\n",
            "\n",
            "    accuracy                           1.00      8719\n",
            "   macro avg       1.00      1.00      1.00      8719\n",
            "weighted avg       1.00      1.00      1.00      8719\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_ada = GRIDS_wo_pm['AdaBoost'].best_estimator_\n",
        "best_extra_tree = GRIDS_wo_pm['ExtraTrees'].best_estimator_\n",
        "print(\"Ada Boost\")\n",
        "clf_performance(X_TrainSet,Y_TrainSet,X_TestSet,Y_TestSet,best_ada, label_map=['loss', 'win'])\n",
        "\n",
        "print(\"Extra Tree\")\n",
        "clf_performance(X_TrainSet,Y_TrainSet,X_TestSet,Y_TestSet, best_extra_tree, label_map=['loss', 'win'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's inspect which features our models used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'feat_selection'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'feat_selection'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pipe_name, pipe \u001b[38;5;129;01min\u001b[39;00m NEW_PIPELINES\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pipe_name)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mfind_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_TrainSet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_TrainSet\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m)\u001b[49m)\n",
            "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36mfind_features\u001b[0;34m(X, fitted_pipe, cols)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_features\u001b[39m(X,fitted_pipe, cols):\n\u001b[0;32m----> 5\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mfitted_pipe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat_selection\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mget_support()\n\u001b[1;32m      6\u001b[0m     X \u001b[38;5;241m=\u001b[39m X_TrainSet\u001b[38;5;241m.\u001b[39mfilter(cols)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'feat_selection'"
          ]
        }
      ],
      "source": [
        "for pipe_name, pipe in NEW_PIPELINES.items():\n",
        "    print(pipe_name)\n",
        "    print(find_features(X_TrainSet,Y_TrainSet,pipe))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
