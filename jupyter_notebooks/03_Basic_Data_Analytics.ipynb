{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Basic Data Analytics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* In this notebook, we will do some preliminary statistical analysis, such as a correlation study, as well as various visualizations.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* The input for this is the cleaned data from the last notebook, namely `'game_data_clean.csv'`.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* At the end, we will have various plots displaying the statistical relationship between different features of our dataset.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "home_dir = '/workspace/pp5-ml-dashboard'\n",
        "csv_dir ='/workspace/pp5-ml-dashboard/outputs/datasets/clean/csv' \n",
        "os.chdir(home_dir)\n",
        "current_dir = os.getcwd()\n",
        "print(current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We now load our cleaned dataset as well as some of the packages that we will be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from src.utils import get_df\n",
        "\n",
        "game_data = get_df('game_data_clean', 'datasets/clean/csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Section 1: Profile report\n",
        "We first examine a profile report based on the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "game_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are going to modify the data frame before doing any exploratory data analysis. We are going to drop metadata columns like `'game_id'`, `'team_id'`, as well as `'Day'` and `'Month'`. We will leave `'Year'` just in case something interesting shows up. We will also need to change the column `'wl_home'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "game_eda = game_data.drop(labels=['game_id','min','season_id', 'team_id_home', 'team_id_away', 'Day', 'Month'], axis=1)\n",
        "game_eda['home_wins'] = game_eda.apply(lambda x: 1 if x['wl_home'] == 'W' else 0, axis=1)\n",
        "game_eda.drop(labels=['wl_home'], axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at a profile report produced by `ydata_profiling`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=game_eda, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is interesting that many of the distributions have the shape of a normal distribution. Some distributions are also skewed. You will notice that there are alerts in the report about zero values. These will not bother us as it took time for 3 point shots to become common and blocks are in general infrequent. The fact that the `'home_wins'` column is 0 approximately 40% of the time is actually a good sign. \n",
        "\n",
        "Let us investigate further if any of these features are normally distributed. A standard proceedure for determining of a distribution is normal is to use the `normality` function from the library Pingouin. If the p-value is larger than 0.05 then we conclude that the distribution is close enough to being normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pingouin as pg\n",
        "\n",
        "normality_eda_nt = pg.normality(game_eda, method='normaltest', alpha=0.05)\n",
        "print(normality_eda_nt.query('normal == True'))\n",
        "print(\"Max p-value Normal Test: \", normality_eda_nt['pval'].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this test, it is clear that these statistics are not normally distributed. However, the distributions sure looked normal. Let's look at some qq plots. We will focus on the statistics\n",
        "\n",
        "Appear normally distributed:\n",
        "* attempted field goals\n",
        "* defensive rebounds\n",
        "* assists\n",
        "\n",
        "Do not appear normally distributed:\n",
        "* made and attempted 3-pointers\n",
        "* blocks\n",
        "\n",
        "The first group appear to be close to normal distributions and the second grouop does not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import probplot\n",
        "\n",
        "good_dists = ['fga','dreb','ast']\n",
        "bad_dists = ['fg3a','fg3m','blk']\n",
        "\n",
        "def prob_plot_home_away(df,vars):\n",
        "    for var in vars:\n",
        "        var_1 = var + '_home'\n",
        "        var_2 = var + '_away'\n",
        "        fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(8, 4))\n",
        "        plt.subplot(121)\n",
        "        probplot(df[var_1], plot=sns.mpl.pyplot)\n",
        "        plt.xlabel(f\"{var_1}\")\n",
        "        plt.subplot(122)\n",
        "        probplot(df[var_2], plot=sns.mpl.pyplot)\n",
        "        plt.xlabel(f\"{var_2}\")\n",
        "        plt.show()\n",
        "\n",
        "prob_plot_home_away(game_eda,good_dists)\n",
        "prob_plot_home_away(game_eda,bad_dists)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At least the curves look similar for home and away teams. Hopefully, we will be able to engineer the features a bit so that they more closely resemble normal distributions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Correlation study\n",
        "Now that we have a basic idea of what the distributions look like, we will focus on correlation coefficients. We will then focus on correlation with respect to the `'home_wins'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_corr = game_eda.corr(method='pearson')\n",
        "spearman_corr = game_eda.corr(method='spearman')\n",
        "spearman_corr.head()\n",
        "\n",
        "# Used in Notebook 05_Model_Selection \n",
        "# print(spearman_corr.filter([ 'reb_home']).loc[['dreb_home','oreb_home']])\n",
        "# spearman_corr.filter([ 'reb_away']).loc[['dreb_away','oreb_away']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will look at the thresholds at which the correlation changes in order to select a reasonable threshold. We will work with the Spearman correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils import count_threshold_changes\n",
        "\n",
        "print(spearman_corr.shape)\n",
        "thresholds = [i/100 for i in range(20,85)]\n",
        "changes = count_threshold_changes(spearman_corr, thresholds)\n",
        "sns.lineplot(x=[change[0] for change in changes], y=[change[1]/2 for change in changes])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are approximately 20 unique pairs of features that have correlation coefficient at least 0.7. Let us see what some of these pairs are and look at the associated scatter plots. Some of these variables should be strongly correlated, like shots attempted and shots made, for various different shots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.utils import get_pairs\n",
        "\n",
        "pairs = get_pairs(spearman_corr,0.7)\n",
        "print(len(pairs))\n",
        "\n",
        "parts = pairs[:5]+pairs[-5:]\n",
        "for index in range(len(parts)//2):\n",
        "    fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(11, 5))\n",
        "    sns.scatterplot(x=parts[2*index][0], y=parts[2*index][1], data=spearman_corr, ax=axes[0])\n",
        "    axes[0].set_title(f\"Corr: {parts[2*index][2]}\")\n",
        "    axes[0].set_ylabel(parts[2*index+1][1])\n",
        "    axes[0].set_xlabel(parts[2*index][0])\n",
        "    sns.scatterplot(x=parts[2*index+1][0], y=parts[2*index+1][1], data=spearman_corr, ax=axes[1])\n",
        "    axes[1].set_title(f\"Corr: {parts[2*index+1][2]}\")\n",
        "    axes[1].set_ylabel(parts[2*index+1][1])\n",
        "    axes[1].set_xlabel(parts[2*index+1][0])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We find it quite interesting that `'Year'` has such a strong correlation with 3 point shots, made and attempted. This isn't so surprising and we would wager that this is related to the impact Steph Curry has had on the game."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now focus on what correlates with the wins. Remember that this is recorded as when the home team wins, so statistics for the away team are functionally statistics for the opponent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_corr_wins = pearson_corr['home_wins'].sort_values(key=abs, ascending=False)[1:]\n",
        "print(pearson_corr_wins[:11])\n",
        "spearman_corr_wins = spearman_corr['home_wins'].sort_values(key=abs, ascending=False)[1:]\n",
        "print(spearman_corr_wins[:11])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `'plus_minus_home'` scores is the difference in points between the home team and the away team. Naturally this will correlate most strongly with winning. Similarly, `'pts'` will correlate quite strongly with winning since that is how the winner of the game is actually determined.\n",
        "\n",
        "We will focus on the 6 next features with that have the strongest correlation with winning. Note that both Pearson and Spearman produce the same list of features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_study = list(pearson_corr_wins[3:9].index)\n",
        "vars_to_study.sort()\n",
        "print(vars_to_study)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The following are the statistics with the least correlation with wins. It is slightly reassuring that the correlation is so weak, but it is a bit odd that it is more strongly correlated with winning than offensive rebounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_corr_wins[-6:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tells an interesting story. Aside from points, the statistic with the highest correlation to wins is the defensive rebounds of the opposing team.\n",
        "\n",
        "Lets look at the distribution of these statistics. We will color the histograms according two which team won. We will also look at box plots and qq plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for var in vars_to_study:\n",
        "    fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(8, 4))\n",
        "    sns.histplot(data=game_eda, x=var, hue='home_wins',kde=True, element=\"step\", ax=axes[0])\n",
        "    plt.subplot(122)\n",
        "    probplot(game_eda[var], plot=sns.mpl.pyplot)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Attention\n",
        "Explain the above graphs a bit more, perhaps before they appear.\n",
        "\n",
        "Note the symmetry in these distributions. Swapping `'home'` to `'away'` is statistically equivalent to reflection across the y-axis. This is good. We would expect such symmetry. It is not necessarily present though as each game only appears once in our data. While these distributions appear normal, we know from the analysis above that they are not. We will attempt to transform them to bring the more in line in the next notebook.\n",
        "\n",
        "## Section 2: Predictive Power Score\n",
        "There is also Predictive Power Score. It is able to measure asymetric relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ppscore as pps\n",
        "\n",
        "pps_raw = pps.matrix(df=game_eda)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pps_results = pps_raw.query('case != \"predict_itself\"').sort_values('ppscore', ascending=False)\n",
        "pps_results = pps_results.filter(['x','y','ppscore'])\n",
        "pps_results.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The score measures the ability of feature `x` to predict the value of feature `y`. It is unsurprising then that `'plus_minus_home'` is completely capable of predicting who wins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pps_rounded = pps_results.query('ppscore!=0')\n",
        "pps_rounded['ppscore'] = pps_rounded.apply(lambda x: round(x['ppscore'],4), axis=1)\n",
        "\n",
        "print(\"mean: \",pps_rounded['ppscore'].mean())\n",
        "print(\"mode: \",pps_rounded['ppscore'].mode())\n",
        "print(\"median: \",pps_rounded['ppscore'].median())\n",
        "print(\"standard deviation: \",pps_rounded['ppscore'].std())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are interested in predicting when the home team wins. So let's focus on that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pps_wins = pps_results.query('y==\"home_wins\"')\n",
        "pps_wins.sort_values('ppscore')\n",
        "print(pps_wins.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems that many of that values are able to predict one another. However, predicting wins seems much more difficult if we don't use the `'plus_minus_home'` value, which is 100% effective. Let's try and determine a reasonable threshold for the pp score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.histplot(data=pps_rounded, x='ppscore', kde=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we look at the change in the number of rows as the threshold increases, it may help us determine an appropriate cut off."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drop_off = count_threshold_changes(pps_rounded['ppscore'],[i/100 for i in range(100)],corr=False)\n",
        "jumps = [(drop_off[index+1][0],-drop_off[index+1][1]+drop_off[index][1]) for index in range(len(drop_off)-1)]\n",
        "print(f\"The number of rows changes {len(jumps)} times.\")\n",
        "plt.plot([jump[0] for jump in jumps],[jump[1] for jump in jumps])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will look at pps values larger than 0.3 and see what statistics show up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pps_truncated = pps_rounded.query('ppscore > 0.3')\n",
        "print(pps_truncated.shape)\n",
        "print(pps_truncated.head())\n",
        "print(pps_truncated.iloc[-5:])\n",
        "pps_table = pps_truncated.pivot(columns='x', index='y', values='ppscore')\n",
        "sns.heatmap(pps_table, annot=True, cmap=\"YlGnBu\", linewidth=0.05,linecolor='lightgrey', xticklabels=True, yticklabels=True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, we see a lot of obvious relationships. Relationships between plus/minus score vs wins, attempted shots vs made shots, and personal fouls vs free throws. One interesting relationship is that between year and 3-point attempts, we also saw this in the correlation study. It is also interesting how little predictive power some statistics have on each other, such as field goals made and field goals attempted. There is also a surprising amount of symmetry in the statistics.\n",
        "\n",
        "Let's consider the predictive power of the features we highlighted in the correlation study."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(vars_to_study)\n",
        "pps_home_wins = pps_results[pps_results['x'].isin(vars_to_study)].query('y==\"home_wins\"')\n",
        "pps_home_wins"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "None of these statistics that have a strong correlation seem to have predictive power. Thus, we don't feel there is a lot of insight to be gained from the `'ppscore'`. Perhaps this is because it is easy to imagine how these statistics influence each other.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "In the next notebook, we will do some feature engineering. In the previous notebook we truncated the data so that we have no missing values. This means we won't have much cleaning to do. We will spend a lot of our time seeing if we can transform our features so that they are closer to normal distributions.\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "Both correlation and pps values confirm common sense related to Basketball, attempts correlates with successes. One standout is the relationship between year and 3 point shots (both made and attempted). We have highlighted some statistics:\n",
        "* Assists (home and away teams)\n",
        "* Defensive Rebounds (home and away teams)\n",
        "* Field Goals Made (home and away teams)\n",
        "\n",
        "In particular, the correlation of the opposing teams number of defensive rebounds had a comparatively strong correlation with winning."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
