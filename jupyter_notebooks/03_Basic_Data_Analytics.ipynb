{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Basic Data Analytics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* In this notebook, we will do some preliminary statistical analysis, such as a correlation study, as well as various visualizations.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* The input for this is the cleaned data from the last notebook, namely `'game_data_clean.csv'`.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* At the end, we will have various plots displaying the statistical relationship between different features of our dataset.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "home_dir = '/workspace/pp5-ml-dashboard'\n",
        "csv_dir ='/workspace/pp5-ml-dashboard/outputs/datasets/clean/csv' \n",
        "os.chdir(home_dir)\n",
        "current_dir = os.getcwd()\n",
        "print(current_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We now load our cleaned dataset as well as some of the packages that we will be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from ydata_profiling import ProfileReport\n",
        "from src.utils import get_df\n",
        "\n",
        "game_data = get_df('game_data_clean', csv_dir)\n",
        "game_data.head()\n",
        "#game_raw = get_df('game')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1: Correlation study and visualization\n",
        "We hypothesize that many of the statistics will be correlated with each other. After dropping certain categorical features, lets look the correlation dataframe.\n",
        "\n",
        "Note: add in playoff and regular season column to see if anything correlates there, and maybe leave year in, or add season in as an ordinal thing. maybe make team ordinal as well. drop day, maybe drop month as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "game_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We are going to modify the data frame before doing computing any exploratory data analysis. We are going to drop metadata  columns like `'game_id'`, `'team_id'`, as well as `'Day'` and `'Month'`. We will leave `'Year'` just in case something interesting shows up. We will also need to change the column `'wl_home'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "game_eda = game_data.drop(labels=['game_id','min','season_id', 'team_id_home', 'team_id_away', 'Day', 'Month'], axis=1)\n",
        "game_eda['home_wins'] = game_eda.apply(lambda x: 1 if x['wl_home'] == 'W' else 0, axis=1)\n",
        "game_eda.drop(labels=['wl_home','wl_away'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at a profile report produced by `ydata_profiling`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=game_eda, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pearson_corr = game_eda.corr(method='pearson')['home_wins'].sort_values(key=abs, ascending=False)[1:]\n",
        "print(pearson_corr[:11])\n",
        "spearman_corr = game_eda.corr(method='spearman')['home_wins'].sort_values(key=abs, ascending=False)[1:]\n",
        "print(spearman_corr[:11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following are the statistics with the least correlation with wins. It is a bit strange that there is any correlation between the home team winning and the year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(pearson_corr[-5:])\n",
        "print(spearman_corr[-5:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This tells an interesting story. Aside from points, the statistic with the highest correlation to wins is the defensive rebounds of the opposing team. What about predictive power? Remember, this statistic is not symmetric.\n",
        "\n",
        "\n",
        "This is a lot of data. So let's look at a heat map where we only consider correlation coefficients the top 9 correlation coefficients. Also, the `'plus_minus'` statistic is just the difference in points. So clearly, this will have the highest correlation with who wins (why is it not a correlation coefficient of 1?). The Spearman and Pearson correlation coefficients indicate the same features for further study. We may also remove the `'pts'` statistics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_study = ['ast_home','ast_away', 'dreb_away', 'dreb_home', 'fgm_away', 'fgm_home', 'pts_away', 'pts_home']\n",
        "top_corr = game_data.filter(list(vars_to_study)+['home_wins'])\n",
        "top_corr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are all numerical fields. So we will plot the distribution of the values and use hue to distinguish between wins and losses. Notice that there is a certain symmetry in the distributions. If the role of home and away are swapped we could also swap win and loss. The symmetry can also be thought of as reflecting across the y-axis. This shows a genuine symmetry in the data since each game is only listed once. The presence of the symmetry is almost reassuring and is very intuitive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for var in vars_to_study:\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(data=game_data_for_corr, x=var, hue='home_wins', kde=True, element=\"step\")\n",
        "    plt.title(f\"{var}\", fontsize=20, y=1.05)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
