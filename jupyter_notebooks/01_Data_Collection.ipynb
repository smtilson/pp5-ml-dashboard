{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Retrieve dataset from Kaggle, save the raw data, and remove unnecessary files.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* One needs their credentials for Kaggle as a json file named `kaggle.json`.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* The output of this folder is a directory named `outputs/datasets/raw/csv` inside  in outputs which contains various CSV files. If the user wishes, they can also keep the database vrersion of the files.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* The steps here are not strictly necessary as the data can be obtained from the following link:  <a href=\"https://www.kaggle.com/datasets/wyattowalsh/basketball\">Wyatt Walsh's NBA Database</a>.\n",
        "\n",
        "* Please select Python 3.8.18 for the kernel of this notebook. It was developed with this version of Python in mind and we can not guarantee the performance using a different kernel.\n",
        "\n",
        "* This notebook was inspired by the Data Collection Jupyter notebook in the Churnometer walkthrough project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "The following cells will change the working directory to the parent folder using commands from the `os` libraray."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set the working directory to:\n",
            "/workspace/pp5-ml-dashboard\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "new_current_dir = os.getcwd()\n",
        "print(f\"You set the working directory to:\\n{new_current_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "source": [
        "The new working directory should be the name of the cloned repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Section 1: Data retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we will collect the zip file containing the data. Depending on when you perform this, the data set may be different from what we have used as the dataset is updated regularly.  This should not effect the performance of the models as our code excludes games after a certain date."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install the kaggle package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle==1.5.12\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle==1.5.12) (1.16.0)\n",
            "Requirement already satisfied: certifi in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle==1.5.12) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle==1.5.12) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle==1.5.12) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /workspace/.pip-modules/lib/python3.8/site-packages (from kaggle==1.5.12) (4.66.4)\n",
            "Collecting python-slugify (from kaggle==1.5.12)\n",
            "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: urllib3 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from kaggle==1.5.12) (2.2.2)\n",
            "Collecting text-unidecode>=1.3 (from python-slugify->kaggle==1.5.12)\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from requests->kaggle==1.5.12) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.8.18/lib/python3.8/site-packages (from requests->kaggle==1.5.12) (3.7)\n",
            "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73025 sha256=719c066c2003bc9aead8c164d8c22a5eab7c188fabb2cc5f850fec28612f3cc4\n",
            "  Stored in directory: /home/gitpod/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
            "Successfully built kaggle\n",
            "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
            "Successfully installed kaggle-1.5.12 python-slugify-8.0.4 text-unidecode-1.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order to download the dataset, you will need your Kaggle authentication tokens. These can be retrieved by navigating to your settings page, scrolling down to the API section, and clicking on the \"Create New Token\" button. This will invalidate your current token and download a new kaggle.json file to your download directory. Copy that json file to your current working directory. Make sure that it is named `kaggle.json`.\n",
        "\n",
        "* It should appear greyed out as the name is in the `gitignore` file already.\n",
        "\n",
        "Now you are ready to execute the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now download the zip file containing the datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading basketball.zip to inputs/datasets/raw\n",
            "100%|███████████████████████████████████████▉| 696M/697M [00:20<00:00, 39.6MB/s]\n",
            "100%|████████████████████████████████████████| 697M/697M [00:20<00:00, 36.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "KaggleDatasetPath = \"wyattowalsh/basketball\"\n",
        "DestinationFolder = \"outputs/datasets/raw\"   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To unzip the dataset execute the following cell. It will also remove your Kaggle tokens as well as the zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  inputs/datasets/raw/basketball.zip\n",
            "  inflating: inputs/datasets/raw/csv/common_player_info.csv  \n",
            "  inflating: inputs/datasets/raw/csv/draft_combine_stats.csv  \n",
            "  inflating: inputs/datasets/raw/csv/draft_history.csv  \n",
            "  inflating: inputs/datasets/raw/csv/game.csv  \n",
            "  inflating: inputs/datasets/raw/csv/game_info.csv  \n",
            "  inflating: inputs/datasets/raw/csv/game_summary.csv  \n",
            "  inflating: inputs/datasets/raw/csv/inactive_players.csv  \n",
            "  inflating: inputs/datasets/raw/csv/line_score.csv  \n",
            "  inflating: inputs/datasets/raw/csv/officials.csv  \n",
            "  inflating: inputs/datasets/raw/csv/other_stats.csv  \n",
            "  inflating: inputs/datasets/raw/csv/play_by_play.csv  \n",
            "  inflating: inputs/datasets/raw/csv/player.csv  \n",
            "  inflating: inputs/datasets/raw/csv/team.csv  \n",
            "  inflating: inputs/datasets/raw/csv/team_details.csv  \n",
            "  inflating: inputs/datasets/raw/csv/team_history.csv  \n",
            "  inflating: inputs/datasets/raw/csv/team_info_common.csv  \n",
            "  inflating: inputs/datasets/raw/nba.sqlite  \n"
          ]
        }
      ],
      "source": [
        "! unzip {DestinationFolder}/*.zip -d {DestinationFolder} \\\n",
        "  && rm {DestinationFolder}/*.zip \\\n",
        "  && rm kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Section 2: Removing unnecessary data\n",
        "\n",
        "We will not be using all of the above data. You are free to peruse it or use it for your own project. Please make sure to credit Wyatt Walsh though for his work in collecting the data and keeping it up to date.\n",
        "\n",
        "We will be keeping the following: (note, this should be double checked at the end of the project)\n",
        "- `game.csv`\n",
        "- `line_score.csv`\n",
        "- `other_stats.csv`\n",
        "- `team_history.csv`\n",
        "\n",
        "Feel free to take a look at the files before we prune the directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['game.csv', 'line_score.csv', 'officials.csv', 'other_stats.csv', 'team_history.csv']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "os.chdir(current_dir+'/outputs/datasets/raw/csv')\n",
        "current_dir = os.getcwd()\n",
        "csv_files = os.listdir(current_dir)\n",
        "print(csv_files)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can load any of the listed files as a data frame and inspect them. We have loaded `game.csv` as this will be the file of primary interest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          season_id  team_id_home       game_id           min      fgm_home  \\\n",
            "count  65698.000000  6.569800e+04  6.569800e+04  65698.000000  65685.000000   \n",
            "mean   22949.338747  1.609926e+09  2.584747e+07    221.003486     39.672269   \n",
            "std     5000.305500  3.324313e+07  6.303760e+06     67.903521      6.770802   \n",
            "min    12005.000000  4.500000e+01  1.050000e+07      0.000000      4.000000   \n",
            "25%    21981.000000  1.610613e+09  2.130053e+07    240.000000     35.000000   \n",
            "50%    21997.000000  1.610613e+09  2.630007e+07    240.000000     40.000000   \n",
            "75%    22011.000000  1.610613e+09  2.880069e+07    240.000000     44.000000   \n",
            "max    42022.000000  1.610617e+09  4.980009e+07    365.000000     84.000000   \n",
            "\n",
            "           fga_home   fg_pct_home     fg3m_home     fg3a_home  fg3_pct_home  \\\n",
            "count  50251.000000  50208.000000  52480.000000  47015.000000  46624.000000   \n",
            "mean      83.992796      0.467321      5.735099     17.741146      0.346136   \n",
            "std        9.164445      0.059423      4.537337     10.545810      0.151234   \n",
            "min        0.000000      0.140000      0.000000      0.000000      0.000000   \n",
            "25%       78.000000      0.427000      2.000000     10.000000      0.261000   \n",
            "50%       84.000000      0.467000      5.000000     16.000000      0.348000   \n",
            "75%       89.000000      0.506000      9.000000     24.000000      0.429750   \n",
            "max      240.000000      0.697000     28.000000     77.000000      1.000000   \n",
            "\n",
            "       ...     dreb_away      reb_away      ast_away      stl_away  \\\n",
            "count  ...  46700.000000  49973.000000  49897.000000  46849.000000   \n",
            "mean   ...     30.238073     42.119645     22.135419      7.854148   \n",
            "std    ...      5.588675      6.867396      5.380805      3.031766   \n",
            "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
            "25%    ...     26.000000     37.000000     18.000000      6.000000   \n",
            "50%    ...     30.000000     42.000000     22.000000      8.000000   \n",
            "75%    ...     34.000000     47.000000     26.000000     10.000000   \n",
            "max    ...     60.000000     90.000000     89.000000     27.000000   \n",
            "\n",
            "           blk_away      tov_away       pf_away      pts_away  \\\n",
            "count  47073.000000  47013.000000  62847.000000  65698.000000   \n",
            "mean       4.681537     15.199860     23.097284    100.991567   \n",
            "std        2.500820      4.299798      5.227208     14.418755   \n",
            "min        0.000000      0.000000      0.000000     19.000000   \n",
            "25%        3.000000     12.000000     20.000000     92.000000   \n",
            "50%        4.000000     15.000000     23.000000    101.000000   \n",
            "75%        6.000000     18.000000     26.000000    110.000000   \n",
            "max       19.000000     40.000000    115.000000    196.000000   \n",
            "\n",
            "       plus_minus_away  video_available_away  \n",
            "count     65698.000000          65698.000000  \n",
            "mean         -3.627569              0.201330  \n",
            "std          13.091395              0.400997  \n",
            "min         -73.000000              0.000000  \n",
            "25%         -12.000000              0.000000  \n",
            "50%          -4.000000              0.000000  \n",
            "75%           5.000000              0.000000  \n",
            "max          68.000000              1.000000  \n",
            "\n",
            "[8 rows x 45 columns]\n",
            "   season_id  team_id_home team_abbreviation_home           team_name_home  \\\n",
            "0      21946    1610610035                    HUS          Toronto Huskies   \n",
            "1      21946    1610610034                    BOM        St. Louis Bombers   \n",
            "2      21946    1610610032                    PRO  Providence Steamrollers   \n",
            "3      21946    1610610025                    CHS            Chicago Stags   \n",
            "4      21946    1610610028                    DEF          Detroit Falcons   \n",
            "\n",
            "    game_id            game_date matchup_home wl_home  min  fgm_home  ...  \\\n",
            "0  24600001  1946-11-01 00:00:00  HUS vs. NYK       L    0      25.0  ...   \n",
            "1  24600003  1946-11-02 00:00:00  BOM vs. PIT       W    0      20.0  ...   \n",
            "2  24600002  1946-11-02 00:00:00  PRO vs. BOS       W    0      21.0  ...   \n",
            "3  24600004  1946-11-02 00:00:00  CHS vs. NYK       W    0      21.0  ...   \n",
            "4  24600005  1946-11-02 00:00:00  DEF vs. WAS       L    0      10.0  ...   \n",
            "\n",
            "   reb_away  ast_away  stl_away  blk_away  tov_away  pf_away  pts_away  \\\n",
            "0       NaN       NaN       NaN       NaN       NaN      NaN      68.0   \n",
            "1       NaN       NaN       NaN       NaN       NaN     25.0      51.0   \n",
            "2       NaN       NaN       NaN       NaN       NaN      NaN      53.0   \n",
            "3       NaN       NaN       NaN       NaN       NaN     22.0      47.0   \n",
            "4       NaN       NaN       NaN       NaN       NaN      NaN      50.0   \n",
            "\n",
            "   plus_minus_away  video_available_away     season_type  \n",
            "0                2                     0  Regular Season  \n",
            "1               -5                     0  Regular Season  \n",
            "2               -6                     0  Regular Season  \n",
            "3              -16                     0  Regular Season  \n",
            "4               17                     0  Regular Season  \n",
            "\n",
            "[5 rows x 55 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "games_df = pd.read_csv('game.csv')\n",
        "\n",
        "games_df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "games_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you can see, the records stretch back quite a ways. The data will need to be truncated as many statistics were not kept track of, hence all of the `NaN` values.\n",
        "\n",
        "Now we remove the files we won't be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully removed officials.csv.\n",
            "team_info_common.csv has already been removed.\n",
            "team.csv has already been removed.\n",
            "team_details.csv has already been removed.\n",
            "inactive_players.csv has already been removed.\n",
            "common_player.csv has already been removed.\n",
            "draft_combine_stats.csv has already been removed.\n",
            "draft_history.csv has already been removed.\n",
            "game_info.csv has already been removed.\n",
            "game_summary.csv has already been removed.\n",
            "play_by_play.csv has already been removed.\n",
            "player.csv has already been removed.\n",
            "nba.sqlite has already been removed.\n"
          ]
        }
      ],
      "source": [
        "for_removal = ['officials.csv','team_info_common.csv','team.csv','team_details.csv','inactive_players.csv','common_player.csv', 'draft_combine_stats.csv','draft_history.csv','game_info.csv','game_summary.csv','play_by_play.csv','player.csv']\n",
        "for file in for_removal:\n",
        "  try:\n",
        "    os.remove(file)\n",
        "  except FileNotFoundError as e:\n",
        "    print(f\"{file} has already been removed.\")\n",
        "  else:\n",
        "    print(f\"Successfully removed {file}.\")\n",
        "\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "try:\n",
        "  os.remove('nba.sqlite')\n",
        "except FileNotFoundError:\n",
        "  print(\"nba.sqlite has already been removed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "In the next notebook, we will begin cleaning the files and preparing them for our models. Below, we remove files we deem unnecessary, you may keep them if you like.\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "We don't yet have any real conclusions. We have collected the data, and now we need to inspect it in order to see what kind of cleaning and preparation it will require."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
